{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Testing infersent to get principal text entailment sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\zaiem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import time\n",
    "import tqdm\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt \n",
    "from operator import itemgetter \n",
    "from nltk.tokenize import word_tokenize\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:425: SourceChangeWarning: source code of class 'models.BLSTMEncoder' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:425: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.LSTM' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# if you are on GPU (encoding ~1000 sentences/s, default)\n",
    "#infersent = torch.load('./encoder/infersent.allnli.pickle')\n",
    "# if you are on CPU (~40 sentences/s)\n",
    "infersent = torch.load('./encoder/infersent.allnli.pickle', map_location=lambda storage, loc: storage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove_path= \"./dataset/GloVe/glove.840B.300d.txt\"\n",
    "infersent.set_glove_path(glove_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'InferSent'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-558155ad2120>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInferSent\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mMODEL_PATH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'encoder/infersent%s.pkl'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mV\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n\u001b[0;32m      5\u001b[0m                 'pool_type': 'max', 'dpout_model': 0.0, 'version': V}\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'InferSent'"
     ]
    }
   ],
   "source": [
    "from models import InferSent\n",
    "V = 2\n",
    "MODEL_PATH = 'encoder/infersent%s.pkl' % V\n",
    "params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
    "                'pool_type': 'max', 'dpout_model': 0.0, 'version': V}\n",
    "infersent = InferSent(params_model)\n",
    "infersent.load_state_dict(torch.load(MODEL_PATH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#You'll have to load the sentences from whose you want to extract keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sentences' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "infersent.build_vocab(sentences, tokenize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "730658"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 45s, sys: 7.58 s, total: 6min 52s\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embeddings = infersent.encode(sentences[0:10000], tokenize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Main keyword extraction function, it encodes the sentence with Infersent than takes the most important words\n",
    "# according to the maxpooling layer\n",
    "def new_visualize(sent, infersent) :\n",
    "    sent = word_tokenize(sent)\n",
    "    if (len(sent)<7) : \n",
    "        number = 3 \n",
    "    elif (len(sent)<10) : \n",
    "        number = 4 \n",
    "    elif (len(sent)<13) :\n",
    "        number = 5 \n",
    "    else :\n",
    "        number = 6 \n",
    "    sent = [['<s>'] + [word for word in sent if word in infersent.word_vec] +\n",
    "            ['</s>']]\n",
    "\n",
    "    if ' '.join(sent[0]) == '<s> </s>':\n",
    "        import warnings\n",
    "        warnings.warn('No words in \"{0}\" have glove vectors. Replacing \\\n",
    "                       by \"<s> </s>\"..'.format(sent))\n",
    "    batch = Variable(infersent.get_batch(sent), volatile=True)\n",
    "    \n",
    "    output = infersent.enc_lstm(batch)[0]\n",
    "    output, idxs = torch.max(output, 0)\n",
    "    # output, idxs = output.squeeze(), idxs.squeeze()\n",
    "    idxs = idxs.data.cpu().numpy()\n",
    "    argmaxs = [np.sum((idxs == k)) for k in range(len(sent[0]))]\n",
    "    important_words_idx= (-np.array(argmaxs)).argsort()[:number].tolist()\n",
    "    important_words= [sent[0][i] for i in important_words_idx]\n",
    "    return important_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_from_function(arr, number, sentence) : \n",
    "    sentence = word_tokenize(sentence )\n",
    "    idxs= (-np.array(arr)).argsort()[:number].tolist()\n",
    "    print(idxs)\n",
    "    return sentence \n",
    "    for i in idxs : \n",
    "        print (sentence[i-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are your favorite and least favorite alcoholic beverages?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 1/10 [00:00<00:01,  4.70it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:00<00:01,  5.12it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alcoholic', 'beverages', 'your', 'favorite', '?']\n",
      "Somewhere backstage, an argument was raging.\n",
      "['raging', 'backstage', 'argument', 'Somewhere']\n",
      "The Irish Free State became reality in 1922.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 3/10 [00:00<00:01,  5.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1922', 'Free', 'Irish', 'reality']\n",
      "How do you fix an HP laptop that won't turn on?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 4/10 [00:00<00:01,  4.72it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HP', 'laptop', '<s>', 'fix', 'How', 'wo']\n",
      "a picture of an old parade going through a town\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.71it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['parade', 'old', 'picture', 'town', 'going']\n",
      "A report on The Methodology of Comparative Research, pp. 1-20.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 6/10 [00:01<00:00,  4.51it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1-20', 'Methodology', 'pp', 'report', 'Research', 'Comparative']\n",
      "A plate of fried fish over a bed of french fries with some sauce in a can.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 7/10 [00:01<00:00,  4.16it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['french', 'plate', 'fries', 'fish', 'fried', 'bed']\n",
      "I've written out the mathematical proposition in English that's easier to understand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 8/10 [00:01<00:00,  4.05it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:02<00:00,  4.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mathematical', 'English', 'easier', \"'ve\", 'proposition', 'written']\n",
      "The alcohol issues involved dangerous drinking.\n",
      "['drinking', 'dangerous', 'issues', 'alcohol']\n",
      "A plate of food with vegetables and meat.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.31it/s]\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plate', 'meat', 'vegetables', 'food']\n"
     ]
    }
   ],
   "source": [
    "# Test on the first ten sentences \n",
    "counters = []\n",
    "for i in tqdm.tqdm(range(len(sentences[0:10]))) : \n",
    "    print(sentences[i])\n",
    "    counters.append(new_visualize(sentences[i], infersent))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/730658 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/730658 [00:00<43:50:22,  4.63it/s]\u001b[A\n",
      "  0%|          | 2/730658 [00:00<39:13:59,  5.17it/s]\u001b[A\n",
      "  0%|          | 3/730658 [00:00<38:31:16,  5.27it/s]\u001b[A\n",
      "  0%|          | 4/730658 [00:00<41:41:27,  4.87it/s]\u001b[A\n",
      "  0%|          | 5/730658 [00:01<41:35:54,  4.88it/s]\u001b[A\n",
      "  0%|          | 6/730658 [00:01<43:12:57,  4.70it/s]\u001b[A\n",
      "  0%|          | 7/730658 [00:01<47:13:55,  4.30it/s]\u001b[A\n",
      "  0%|          | 8/730658 [00:01<48:41:59,  4.17it/s]\u001b[A\n",
      "  0%|          | 9/730658 [00:02<46:45:13,  4.34it/s]\u001b[A\n",
      "  0%|          | 10/730658 [00:02<45:54:30,  4.42it/s]\u001b[A\n",
      "  0%|          | 11/730658 [00:02<48:57:37,  4.15it/s]\u001b[A\n",
      "  0%|          | 12/730658 [00:02<48:01:47,  4.23it/s]\u001b[A\n",
      "  0%|          | 13/730658 [00:03<54:07:48,  3.75it/s]\u001b[A\n",
      "  0%|          | 14/730658 [00:03<52:46:14,  3.85it/s]\u001b[A\n",
      "  0%|          | 15/730658 [00:03<51:59:38,  3.90it/s]\u001b[A\n",
      "  0%|          | 16/730658 [00:04<53:09:39,  3.82it/s]\u001b[A\n",
      "  0%|          | 17/730658 [00:04<54:18:08,  3.74it/s]\u001b[A\n",
      "  0%|          | 18/730658 [00:04<54:31:04,  3.72it/s]\u001b[A\n",
      "  0%|          | 19/730658 [00:04<53:14:48,  3.81it/s]\u001b[A\n",
      "  0%|          | 20/730658 [00:05<53:42:29,  3.78it/s]\u001b[A\n",
      "  0%|          | 21/730658 [00:05<53:13:16,  3.81it/s]\u001b[A\n",
      "  0%|          | 22/730658 [00:05<53:42:31,  3.78it/s]\u001b[A\n",
      "  0%|          | 23/730658 [00:06<53:05:06,  3.82it/s]\u001b[A\n",
      "  0%|          | 24/730658 [00:06<51:47:23,  3.92it/s]\u001b[A\n",
      "  0%|          | 25/730658 [00:06<52:05:52,  3.90it/s]\u001b[A\n",
      "  0%|          | 26/730658 [00:06<51:57:58,  3.91it/s]\u001b[A\n",
      "  0%|          | 27/730658 [00:06<51:32:19,  3.94it/s]\u001b[A\n",
      "  0%|          | 28/730658 [00:07<53:14:11,  3.81it/s]\u001b[A\n",
      "  0%|          | 29/730658 [00:07<53:02:36,  3.83it/s]\u001b[A\n",
      "  0%|          | 30/730658 [00:07<52:34:01,  3.86it/s]\u001b[A\n",
      "  0%|          | 31/730658 [00:07<52:09:27,  3.89it/s]\u001b[A\n",
      "  7%|▋         | 53299/730658 [3:57:15<50:15:16,  3.74it/s]/Users/salah/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: No words in \"[['<s>', '</s>']]\" have glove vectors. Replacing                        by \"<s> </s>\"..\n",
      "100%|██████████| 730658/730658 [54:12:58<00:00,  3.74it/s]   \n"
     ]
    }
   ],
   "source": [
    "expanders = []\n",
    "for i in tqdm.tqdm(range(len(sentences))) : \n",
    "    expanders.append(new_visualize(sentences[i], infersent))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['television', 'big', 'screen', 'room', 'sitting', 'stand'],\n",
       " ['Acid', 'Rain', 'state-of-the-art', 'data', 'cap', 'administered'],\n",
       " ['<s>', 'i', 'used', 'before', '</s>'],\n",
       " ['ban', 'products', 'China', 'India', 'Should'],\n",
       " ['avoid', 'thinking', 'lots'],\n",
       " ['suitcase', 'bed', 'sitting', 'woman', 'on'],\n",
       " ['restaurant', 'street', 'standing', 'sign', 'on', 'A'],\n",
       " ['depot', 'clock', 'blue', 'travels', 'atop', 'sits'],\n",
       " ['Church', 'spire', 'capped', 'mountains', 'tops'],\n",
       " ['War', 'III', 'break', 'World']]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print random expansions  \n",
    "expanders[10000:10010]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
